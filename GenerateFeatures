## Importing necessary nltk packages
#ToDo minimise imports

from nltk.tokenize import RegexpTokenizer, TweetTokenizer, sent_tokenize
import re
import nltk
nltk.download("popular")
from nltk import *
from nltk.corpus import stopwords

#Defining individual features

def sentence_count(input_text):
    """
    count the number of sentences in tweet
    """
    count = len(sent_tokenize(input_text))
    return count

def word_count(input_text):
    '''
    Counts words in input string
    '''
    re_tokenizer = RegexpTokenizer(r'\w+') #using regexp to not count punctuation
    tokens = re_tokenizer.tokenize(input_text)

    word_count = 0
    for token in tokens:
      word_count += 1
            
    return word_count


def stopword_ratio(input_text):
    """
    return ration of stopwords on total words in tweet
    """
    tokenizer = RegexpTokenizer(r'\w+')
    tokens = tokenizer.tokenize(input_text)
    word_count = len(tokens)
    
    StopWords = set(stopwords.words('english'))
    stopword_count = 0
    for token in tokens:
        if token in StopWords:
            stopword_count += 1
    
    ratio = 0
    if word_count != 0:
        ratio = stopword_count / word_count
    
    return ratio


def count_hashtags(input_text):
  """
  Counts the number of hashtags in the text
  """
  return input_text.count('#')


def count_mentions(input_text):
  """
  counts mentions in the text, N.B. mentions are @someone
  """
  return input_text.count('@')

def count_punctuation(input_tex):
  """
  counts all punctuation
  """
  return input_text.count(string.punctuation)
  
# Parametric function to call all single feature generation functions at once
  
def text_preprocessing(df, lemmatize = True, count_sentences = True, ):
  """
  Takes a DataFrame as input, returns the df with added columns and a list with the names of added columns. 
  By default column to be processed is named 'text', change text_column_name parameter. 
  All features are generated by default, you can turn off individual ones in parameters.
  """
  df['lemmatized_text'] = (df['text']).apply(remove_mentions_hashtags).apply(lemmatize_text)
  df['sentence_count'] = (df['text']).apply(sentence_count)
  df['mention_count'] = (df['text']).apply(count_mentions)
  df['hashtag_count'] = (df['text']).apply(count_hashtags)
  df['word_count'] = (df['text']).apply(remove_mentions_hashtags).apply(word_count)
  df['stopword_ratio'] = (df['text']).apply(remove_mentions_hashtags).apply(stopword_ratio)
  return df

generated_features = ['sentence_count', 'mention_count', 'hashtag_count', 'word_count',
       'stopword_ratio']
