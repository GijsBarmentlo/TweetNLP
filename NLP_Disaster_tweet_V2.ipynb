{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "NLP_Disaster tweet_V2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "b_SKMrZFQe8j",
        "ciMEw21rWKz-",
        "lAcbvB4hXtpb",
        "cVMK9F2IcV8X",
        "ptyI6rRZlQMu",
        "IBpF6JqMyaOQ",
        "2BJe5HHJyf1W",
        "ZG2QsvZU_I8h",
        "kUc-NA3aEzg-",
        "ht8sq879FxUY",
        "8ucTszK7Qe8o",
        "shG54pocJVSv",
        "nfTwvHZbQe-C",
        "wCF3gCScQe-E",
        "6JYW6fvlQe-p",
        "epEmHol7GGhu",
        "SnQ_Nl-Jsppm",
        "suimN4H8F7du",
        "swJJv9eaQe-9"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GijsBarmentlo/TweetNLP/blob/master/NLP_Disaster_tweet_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARNQsQMEjK7x",
        "colab_type": "text"
      },
      "source": [
        "# Imports + open drive + Kaggle API\n",
        "Setup environment and link to google drive for file storage and Kaggle API for submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "URs1FHmNQe7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pshjRo-0I7FF",
        "colab_type": "code",
        "outputId": "2f9dedfe-d2ef-48e9-95b2-d9708a7ba1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "#setup kaggle for submission\n",
        "\n",
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "!ls -a"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            ".  ..  .config\tgdrive\t.kaggle  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT8tF2OS3oNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\": \"gijske\" ,\"key\":\"9e096df0b412d13bc210ea18ad893557\"}\n",
        "\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx1ZJuKw-U1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /content/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkfvaqgsFVF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiKn7kjuFYQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c65391b6-1004-425b-e801-302def7b72f3"
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4xjq9tjQteI",
        "colab_type": "code",
        "outputId": "7c0a4f27-9461-4393-e1a1-3195567fda5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#use my drive as HDD\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "colab_dir = \"/content/gdrive/My Drive/Colab Data/\"\n",
        "root_dir = \"/content/gdrive/My Drive/Colab Data/Tweet_classification/\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_SKMrZFQe8j",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKqgy5vrrUrW",
        "colab_type": "text"
      },
      "source": [
        "## reading data\n",
        "Read train and test data (.csv) as dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xo0VtL-7Qe8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "_haCx5DbQe72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv(root_dir + \"train.csv\")\n",
        "test_df = pd.read_csv(root_dir + \"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "k6JwVVTCQe8I",
        "colab_type": "code",
        "outputId": "56b44b76-c5dd-4831-97f2-2369de00c8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciMEw21rWKz-",
        "colab_type": "text"
      },
      "source": [
        "## Keyword : Cleaning and handling NaN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V3rn6VfXRic",
        "colab_type": "code",
        "outputId": "06c58125-c544-4932-917b-e511d53f8a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_df.keyword.nunique()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzaPExZ6Xc8A",
        "colab_type": "code",
        "outputId": "846ed45c-bd04-4dae-b789-8f7cfffb9444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_df.keyword.unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
              "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
              "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
              "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
              "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
              "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
              "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
              "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
              "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
              "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
              "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
              "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
              "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
              "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
              "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
              "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
              "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
              "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
              "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
              "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
              "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
              "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
              "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
              "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
              "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
              "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
              "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
              "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
              "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
              "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
              "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
              "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
              "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
              "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
              "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
              "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
              "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
              "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
              "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
              "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
              "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
              "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
              "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
              "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
              "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
              "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES8Q8H7-Yt7l",
        "colab_type": "text"
      },
      "source": [
        "there are 221 unique values, spaces are saved as \"%20\", we will need to clean that in preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-ekrqcbOo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_keyword(keyword):\n",
        "  if isinstance(keyword, str):\n",
        "    return keyword.replace('%20',' ')\n",
        "  else :\n",
        "    return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnLpltadbVOE",
        "colab_type": "code",
        "outputId": "2657cb4e-ad83-4150-f452-999be7e408c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_df.keyword.isna().sum()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JffOF6WbwJY",
        "colab_type": "text"
      },
      "source": [
        "missing values will need to be handled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDyxmtaiZILs",
        "colab_type": "code",
        "outputId": "905dc29d-f008-4062-c4db-6a9f5fe2643d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "test_df.keyword.nunique()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlHvKpqyZNBs",
        "colab_type": "code",
        "outputId": "2f4e54dc-6437-4f2b-e631-44bc48e52686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "test_df.keyword.unique()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
              "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
              "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
              "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
              "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
              "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
              "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
              "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
              "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
              "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
              "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
              "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
              "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
              "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
              "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
              "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
              "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
              "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
              "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
              "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
              "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
              "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
              "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
              "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
              "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
              "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
              "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
              "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
              "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
              "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
              "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
              "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
              "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
              "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
              "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
              "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
              "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
              "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
              "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
              "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
              "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
              "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
              "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
              "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
              "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
              "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izL88SAUZR6f",
        "colab_type": "code",
        "outputId": "71db519f-bc22-461b-dcd8-c9e7b09e7d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "test_df.keyword.unique() == train_df.keyword.unique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmzCc8NxZj5n",
        "colab_type": "text"
      },
      "source": [
        "Keywords are the same in both test and train data, which means we can oh encode them if we want. This could pose a problem for generalisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAcbvB4hXtpb",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning and lemming text\n",
        "Using spacy, remove stopwords, hashtags, mentions and punctuation.\n",
        "Function definition only, no modifications made to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuXEa8lCXyE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def lemmatize_text(input_string, remove_stopwords = True):\n",
        "  lemmatized_text = \"\"\n",
        "\n",
        "  spacy_doc = nlp(input_string)\n",
        "  if remove_stopwords == False:\n",
        "    for token in spacy_doc:\n",
        "      lemmatized_text = lemmatized_text + ' ' + token.lemma_\n",
        "\n",
        "  if remove_stopwords:\n",
        "    for token in spacy_doc:\n",
        "      if token.is_stop == False:\n",
        "        lemmatized_text = lemmatized_text + \" \" + token.lemma_\n",
        "\n",
        "  return lemmatized_text\n",
        "\n",
        "def remove_mentions_hashtags(input_text):\n",
        "  \"\"\"\n",
        "  Removes # and @\n",
        "  \"\"\"\n",
        "  clean_text = re.sub(r'@\\w+', '', input_text)\n",
        "  clean_text = clean_text.replace(\"#\", \"\")\n",
        "  return clean_text\n",
        "\n",
        "\n",
        "def remove_punctuation(input_text):\n",
        "  \"\"\"\n",
        "  Takes input string and returns string without punctuation\n",
        "  \"\"\"\n",
        "  clean_text = re.sub(r'[^\\w\\s]','',input_text)\n",
        "  return clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz2ijHFiaU1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lemmatize_text(\"we are doing this better, i think\", remove_stopwords = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVMK9F2IcV8X",
        "colab_type": "text"
      },
      "source": [
        "## Feature generation\n",
        "Using NLTK, these functions generate features from the input text. Function definition only, no modifications made to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDpJBLRAPDB1",
        "colab_type": "code",
        "outputId": "2e93221c-0c50-4f48-91c8-ba365c68ec68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer, TweetTokenizer, sent_tokenize\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from nltk import *\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKfQB-oIcXyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_count(input_text):\n",
        "    \"\"\"\n",
        "    count the number of sentences in tweet\n",
        "    \"\"\"\n",
        "    count = len(sent_tokenize(input_text))\n",
        "    return count\n",
        "\n",
        "def word_count(input_text):\n",
        "    '''\n",
        "    Counts words in input string\n",
        "    '''\n",
        "    re_tokenizer = RegexpTokenizer(r'\\w+') #using regexp to not count punctuation\n",
        "    tokens = re_tokenizer.tokenize(input_text)\n",
        "\n",
        "    word_count = 0\n",
        "    for token in tokens:\n",
        "      word_count += 1\n",
        "            \n",
        "    return word_count\n",
        "\n",
        "\n",
        "def stopword_ratio(input_text):\n",
        "    \"\"\"\n",
        "    return ration of stopwords on total words in tweet\n",
        "    \"\"\"\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(input_text)\n",
        "    word_count = len(tokens)\n",
        "    \n",
        "    StopWords = set(stopwords.words('english'))\n",
        "    stopword_count = 0\n",
        "    for token in tokens:\n",
        "        if token in StopWords:\n",
        "            stopword_count += 1\n",
        "    \n",
        "    ratio = 0\n",
        "    if word_count != 0:\n",
        "        ratio = stopword_count / word_count\n",
        "    \n",
        "    return ratio\n",
        "\n",
        "\n",
        "def count_hashtags(input_text):\n",
        "  \"\"\"\n",
        "  Counts the number of hashtags in the text\n",
        "  \"\"\"\n",
        "  return input_text.count('#')\n",
        "\n",
        "\n",
        "def count_mentions(input_text):\n",
        "  \"\"\"\n",
        "  counts mentions in the text, N.B. mentions are @someone\n",
        "  \"\"\"\n",
        "  return input_text.count('@')\n",
        "\n",
        "def count_punctuation(input_tex):\n",
        "  \"\"\"\n",
        "  counts all punctuation\n",
        "  \"\"\"\n",
        "  return input_text.count(string.punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptyI6rRZlQMu",
        "colab_type": "text"
      },
      "source": [
        "## Wrapper\n",
        "Defines a function \"text_preprocessing(df)\" which applies both cleaning, lemming and feature generation to a dataframe's \"text\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0yD6wima2P4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocessing(df):\n",
        "  df['keyword'] = (df['keyword'].apply(clean_keyword))\n",
        "  df['lemmatized_text'] = (df['text']).apply(remove_mentions_hashtags).apply(lemmatize_text)\n",
        "  df['sentence_count'] = (df['text']).apply(sentence_count)\n",
        "  df['mention_count'] = (df['text']).apply(count_mentions)\n",
        "  df['hashtag_count'] = (df['text']).apply(count_hashtags)\n",
        "  df['word_count'] = (df['text']).apply(remove_mentions_hashtags).apply(word_count)\n",
        "  df['stopword_ratio'] = (df['text']).apply(remove_mentions_hashtags).apply(stopword_ratio)\n",
        "  return df\n",
        "\n",
        "generated_features = ['sentence_count', 'mention_count', 'hashtag_count', 'word_count',\n",
        "       'stopword_ratio']\n",
        "generated_features_count = len(generated_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ge1qnuAm0Wy",
        "colab_type": "text"
      },
      "source": [
        "# Word embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7UCalGQEtt1",
        "colab_type": "text"
      },
      "source": [
        "## Spacy pre-trained\n",
        "Using spacy's pretrained 300dim word embedding, create a numpy array composed of the numerical features we generated from the text and the sum of each word's embedded vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGeoUlxMn4ZB",
        "colab_type": "code",
        "outputId": "a7308fb9-fc61-4a6e-9888-0dd8fae8f185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        }
      },
      "source": [
        "#import spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip install -U spacy[cuda100]\n",
        "gpu = spacy.prefer_gpu()\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Requirement already up-to-date: spacy[cuda100] in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.6.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: cupy-cuda100>=5.0.0b4; extra == \"cuda100\" in /usr/local/lib/python3.6/dist-packages (from spacy[cuda100]) (8.0.0b2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda100]) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: fastrlock>=0.3 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda100>=5.0.0b4; extra == \"cuda100\"->spacy[cuda100]) (0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy[cuda100]) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brnPckXltOWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_X(df, chosen_features = generated_features, column_to_emb = 'lemmatized_text'):\n",
        "\n",
        "  df = text_preprocessing(df)\n",
        "\n",
        "  if column_to_emb not in df.columns :\n",
        "    printf(f'dataframe does not contain column named {column_to_emb}')\n",
        "    return\n",
        "\n",
        "  with nlp.disable_pipes():\n",
        "    doc_vecs = np.array([nlp(text).vector for text in df['text']])\n",
        "    keyword_vec = np.array([nlp(keyword).vector for keyword in df['keyword']])\n",
        "    X = np.hstack((doc_vecs, df[chosen_features]))\n",
        "    X = np.hstack((X,keyword_vec))\n",
        "\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6DEcM5ZGvMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Todo make a clean embedder funciton that just takes text column and returns np.array ; WIP\n",
        "\n",
        "def spacy_embed(df, column_to_emb = 'lemmatized_text'):\n",
        "\n",
        "  df = text_preprocessing(df)\n",
        "\n",
        "  if column_to_emb not in df.columns :\n",
        "    printf(f'dataframe does not contain column named {column_to_emb}')\n",
        "    return\n",
        "\n",
        "  with nlp.disable_pipes():\n",
        "    emb_vecs = [nlp(text).vector for text in df[column_to_emb]]\n",
        "    X = np.array(emb_vecs)\n",
        "\n",
        "  return X\n",
        "\n",
        "#embedded_text = spacy_embed(df, column_to_emb = 'lemmatized_text')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb5P0MrGExMZ",
        "colab_type": "text"
      },
      "source": [
        "## ToDo : My own implementation of word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM5NTL1MyGAe",
        "colab_type": "text"
      },
      "source": [
        "# Models\n",
        "We're gonna try a few types of models, simple first, complicated later. This will allow us to benchmark performance and avoid needless effort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2QsvZU_I8h",
        "colab_type": "text"
      },
      "source": [
        "## Ridge classifier\n",
        "They perform well on this type of tasks as they are better at taking weak signals into account"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45V9bOtC_Lrw",
        "colab_type": "code",
        "outputId": "b6e3f965-040f-48be-e490-3f81d7b8034a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "#basic ridge classifier, used for handling n>m & adding needed bias\n",
        "ridge_clf = linear_model.RidgeClassifierCV()\n",
        "\n",
        "#basic evaluation\n",
        "scores = model_selection.cross_val_score(ridge_clf, X, train_df.target, cv=10, scoring=\"f1\")\n",
        "print(f\"average f1 score with CV {scores.mean()}\")\n",
        "scores = model_selection.cross_val_score(ridge_clf, X, train_df.target, cv=10, scoring=\"accuracy\")\n",
        "print(f\"average accuracy score with CV {scores.mean()}\")\n",
        "\n",
        "#fit model\n",
        "ridge_clf.fit(X,train_df.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average f1 score with CV 0.7174758499213684\n",
            "average accuracy score with CV 0.770393114461218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeClassifierCV(alphas=array([ 0.1,  1. , 10. ]), class_weight=None, cv=None,\n",
              "                  fit_intercept=True, normalize=False, scoring=None,\n",
              "                  store_cv_values=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seAVfhglDd6f",
        "colab_type": "text"
      },
      "source": [
        "We get 0.72 f1 and 76% accuracy, let's improve with a simple neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUc-NA3aEzg-",
        "colab_type": "text"
      },
      "source": [
        "## Random forest\n",
        "Same reasoning here, a rf will make sure some trees are optimised for the weaker features which seems key in an NLP task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyU-vm4FE3B0",
        "colab_type": "code",
        "outputId": "4671e477-80c0-4361-a007-dccda15bffa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "scores = model_selection.cross_val_score(rf_clf, X, train_df.target, cv=7, scoring=\"f1\")\n",
        "print(f\"average f1 score with CV {scores.mean()}\")\n",
        "scores = model_selection.cross_val_score(rf_clf, X, train_df.target, cv=7, scoring=\"accuracy\")\n",
        "print(f\"average accuracy score with CV {scores.mean()}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average f1 score with CV 0.6922235464996395\n",
            "average accuracy score with CV 0.7627778974975455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiGO8AdUyXTv",
        "colab_type": "text"
      },
      "source": [
        "## Dense NN\n",
        "Let's see what results we can get with a dense neural network, sticking to Keras for simplicity and legibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBpF6JqMyaOQ",
        "colab_type": "text"
      },
      "source": [
        "### Loss function\n",
        "We will evaluate this model by F1 score as it is a binary classification problem and there is no reason to give big priority to either precision or recall. There is no longer a built F1 score in Keras so we will need to implement a differentiable F1 ourselves\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjV4aZs0ydIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2072e5dd-f863-4c0f-9dd3-10bdf1e17cfb"
      },
      "source": [
        "#F1 score and differentiable f1 loss\n",
        "\n",
        "import keras.backend as K\n",
        "\n",
        "def f1_score(y_true, y_pred): #taken from old keras source code\n",
        "  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "  precision = true_positives / (predicted_positives + K.epsilon())\n",
        "  recall = true_positives / (possible_positives + K.epsilon())\n",
        "  f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "  return f1_val\n",
        "\n",
        "\n",
        "# Taken from this kernel https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric , my thanks to Michal\n",
        "import tensorflow as tf\n",
        "\n",
        "def f1_loss(y_true, y_pred):\n",
        "    \n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return 1 - K.mean(f1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BJe5HHJyf1W",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions\n",
        "A plot function that will take history as input and plot loss, accuracy and f1, this will make it easier to quickly evaluate performance and iterate over hyperparameters for the the NN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-iS2VZ-yiFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#graph results\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def plot_history(history):\n",
        "  keys = history.history.keys()\n",
        "  metric_present = False\n",
        "\n",
        "  #Loss graph\n",
        "  for key in keys :\n",
        "    if 'loss' in key:\n",
        "      plt.plot(history.history[key])\n",
        "      metric_present = True\n",
        "\n",
        "  if metric_present:\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['val', 'train'], loc='upper left')\n",
        "    plt.show()\n",
        "    metric_present = False\n",
        "\n",
        "\n",
        "  #accuracy graph\n",
        "  for key in keys :\n",
        "    if 'acc' in key:\n",
        "      plt.plot(history.history[key])\n",
        "      metric_present = True\n",
        "    \n",
        "  if metric_present:\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['val', 'train'], loc='upper left')\n",
        "    plt.show()\n",
        "    metric_present = False\n",
        "\n",
        "  #f1 graph\n",
        "  for key in keys :\n",
        "    if 'f1' in key:\n",
        "      plt.plot(history.history[key])\n",
        "      metric_present = True\n",
        "    \n",
        "  if metric_present:\n",
        "    plt.title('F1 score')\n",
        "    plt.ylabel('F1')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['val', 'train'], loc='upper left')\n",
        "    plt.show()\n",
        "    metric_present = False  \n",
        "\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fsa-28T0z9-",
        "colab_type": "text"
      },
      "source": [
        "### Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J_mgFR200hX",
        "colab_type": "code",
        "outputId": "60934485-eb8c-49b8-b049-a7a359f07796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Make a numpy array as input for the NN, \n",
        "X_nf = make_X(train_df, column_to_emb = 'lemmatized_text')\n",
        "X_train_nf , X_val_nf, y_train_nf, y_val_nf = train_test_split(X_nf, train_df.target , test_size=0.2, random_state=42)\n",
        "X_nf.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 605)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01zjlIOxyy7W",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1EGqOP_y5CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Packages for modeling\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdL0_bNuFv4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model(input_dimension = X_nf.shape[1], layer_list = [600, 300, 100, 100, 100, 100, 100, 100, 100, 100, 100], optimiser = 'adam'):\n",
        "  \n",
        "  #Make model and input layer\n",
        "  made_model = models.Sequential()\n",
        "  made_model.add(layers.Dense(600, input_dim = input_dimension, activation = 'relu'))\n",
        "\n",
        "  #Add hidden layers\n",
        "  for number_of_neurons in layer_list:\n",
        "    made_model.add(layers.Dense(number_of_neurons, activation = 'relu'))\n",
        "\n",
        "  #Add output layer\n",
        "  made_model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "  #Compile\n",
        "  made_model.compile(loss = f1_loss, optimizer = optimiser, metrics=['accuracy', f1_score])\n",
        "\n",
        "  #print summary\n",
        "  printf('made this model with made_model function')\n",
        "  printf(made_model.summary())\n",
        "\n",
        "  return made_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rwqN0TLHN-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "375ae60d-d708-475c-fbe2-a7d6487a6afd"
      },
      "source": [
        "thin_model = make_model(layer_list = [600, 300, 100, 100, 100, 100, 100, 100])\n",
        "thin_model.summary()\n",
        "thin_history = thin_model.fit(X_train_nf, y_train_nf, batch_size = 1015, epochs = 150, validation_data = (X_val_nf, y_val_nf))\n",
        "\n",
        "plot_history(thin_history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6090 samples, validate on 1523 samples\n",
            "Epoch 1/150\n",
            "6090/6090 [==============================] - 108s 18ms/step - loss: 0.4580 - accuracy: 0.4371 - f1_score: 0.5948 - val_loss: 0.4019 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 2/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3979 - accuracy: 0.4305 - f1_score: 0.6019 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 3/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3983 - accuracy: 0.4305 - f1_score: 0.6017 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 4/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3981 - accuracy: 0.4305 - f1_score: 0.6019 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 5/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3982 - accuracy: 0.4305 - f1_score: 0.6018 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 6/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3981 - accuracy: 0.4305 - f1_score: 0.6019 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 7/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3981 - accuracy: 0.4305 - f1_score: 0.6019 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 8/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3983 - accuracy: 0.4305 - f1_score: 0.6016 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 9/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3981 - accuracy: 0.4305 - f1_score: 0.6018 - val_loss: 0.4024 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 10/150\n",
            "6090/6090 [==============================] - 108s 18ms/step - loss: 0.3980 - accuracy: 0.4305 - f1_score: 0.6019 - val_loss: 0.4023 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 11/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3977 - accuracy: 0.4305 - f1_score: 0.6019 - val_loss: 0.4025 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 12/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3960 - accuracy: 0.4305 - f1_score: 0.6018 - val_loss: 0.3965 - val_accuracy: 0.4261 - val_f1_score: 0.5974\n",
            "Epoch 13/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3784 - accuracy: 0.5333 - f1_score: 0.6326 - val_loss: 0.3660 - val_accuracy: 0.5831 - val_f1_score: 0.6540\n",
            "Epoch 14/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3386 - accuracy: 0.6309 - f1_score: 0.6678 - val_loss: 0.3389 - val_accuracy: 0.5962 - val_f1_score: 0.6682\n",
            "Epoch 15/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3087 - accuracy: 0.6836 - f1_score: 0.6913 - val_loss: 0.2906 - val_accuracy: 0.6999 - val_f1_score: 0.7159\n",
            "Epoch 16/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3242 - accuracy: 0.7222 - f1_score: 0.6765 - val_loss: 0.3302 - val_accuracy: 0.6093 - val_f1_score: 0.6738\n",
            "Epoch 17/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3400 - accuracy: 0.5737 - f1_score: 0.6599 - val_loss: 0.3671 - val_accuracy: 0.5227 - val_f1_score: 0.6364\n",
            "Epoch 18/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3485 - accuracy: 0.5545 - f1_score: 0.6513 - val_loss: 0.3529 - val_accuracy: 0.5581 - val_f1_score: 0.6515\n",
            "Epoch 19/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.3218 - accuracy: 0.6192 - f1_score: 0.6787 - val_loss: 0.3014 - val_accuracy: 0.6704 - val_f1_score: 0.7030\n",
            "Epoch 20/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2892 - accuracy: 0.6943 - f1_score: 0.7109 - val_loss: 0.2900 - val_accuracy: 0.6967 - val_f1_score: 0.7138\n",
            "Epoch 21/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2767 - accuracy: 0.7287 - f1_score: 0.7233 - val_loss: 0.2727 - val_accuracy: 0.7551 - val_f1_score: 0.7317\n",
            "Epoch 22/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2918 - accuracy: 0.7498 - f1_score: 0.7078 - val_loss: 0.2705 - val_accuracy: 0.7577 - val_f1_score: 0.7336\n",
            "Epoch 23/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2758 - accuracy: 0.7486 - f1_score: 0.7241 - val_loss: 0.2731 - val_accuracy: 0.7544 - val_f1_score: 0.7341\n",
            "Epoch 24/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2810 - accuracy: 0.7560 - f1_score: 0.7190 - val_loss: 0.2774 - val_accuracy: 0.7715 - val_f1_score: 0.7328\n",
            "Epoch 25/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2834 - accuracy: 0.7547 - f1_score: 0.7163 - val_loss: 0.2762 - val_accuracy: 0.7459 - val_f1_score: 0.7316\n",
            "Epoch 26/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2761 - accuracy: 0.7323 - f1_score: 0.7236 - val_loss: 0.2936 - val_accuracy: 0.6927 - val_f1_score: 0.7097\n",
            "Epoch 27/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2846 - accuracy: 0.7056 - f1_score: 0.7154 - val_loss: 0.2957 - val_accuracy: 0.6848 - val_f1_score: 0.7080\n",
            "Epoch 28/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2789 - accuracy: 0.7122 - f1_score: 0.7212 - val_loss: 0.2733 - val_accuracy: 0.7269 - val_f1_score: 0.7305\n",
            "Epoch 29/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2718 - accuracy: 0.7425 - f1_score: 0.7284 - val_loss: 0.2658 - val_accuracy: 0.7649 - val_f1_score: 0.7420\n",
            "Epoch 30/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2821 - accuracy: 0.7616 - f1_score: 0.7179 - val_loss: 0.2769 - val_accuracy: 0.7735 - val_f1_score: 0.7327\n",
            "Epoch 31/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2742 - accuracy: 0.7685 - f1_score: 0.7253 - val_loss: 0.2715 - val_accuracy: 0.7695 - val_f1_score: 0.7356\n",
            "Epoch 32/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2669 - accuracy: 0.7734 - f1_score: 0.7331 - val_loss: 0.2719 - val_accuracy: 0.7708 - val_f1_score: 0.7356\n",
            "Epoch 33/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2645 - accuracy: 0.7711 - f1_score: 0.7355 - val_loss: 0.2582 - val_accuracy: 0.7603 - val_f1_score: 0.7450\n",
            "Epoch 34/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2576 - accuracy: 0.7558 - f1_score: 0.7421 - val_loss: 0.2678 - val_accuracy: 0.7321 - val_f1_score: 0.7354\n",
            "Epoch 35/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2642 - accuracy: 0.7353 - f1_score: 0.7357 - val_loss: 0.2704 - val_accuracy: 0.7282 - val_f1_score: 0.7318\n",
            "Epoch 36/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2544 - accuracy: 0.7622 - f1_score: 0.7458 - val_loss: 0.2590 - val_accuracy: 0.7728 - val_f1_score: 0.7500\n",
            "Epoch 37/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2502 - accuracy: 0.7759 - f1_score: 0.7497 - val_loss: 0.2584 - val_accuracy: 0.7538 - val_f1_score: 0.7456\n",
            "Epoch 38/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2577 - accuracy: 0.7529 - f1_score: 0.7420 - val_loss: 0.2729 - val_accuracy: 0.7262 - val_f1_score: 0.7290\n",
            "Epoch 39/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2648 - accuracy: 0.7365 - f1_score: 0.7351 - val_loss: 0.2716 - val_accuracy: 0.7315 - val_f1_score: 0.7298\n",
            "Epoch 40/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2544 - accuracy: 0.7616 - f1_score: 0.7455 - val_loss: 0.2603 - val_accuracy: 0.7630 - val_f1_score: 0.7470\n",
            "Epoch 41/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2553 - accuracy: 0.7686 - f1_score: 0.7448 - val_loss: 0.2587 - val_accuracy: 0.7656 - val_f1_score: 0.7481\n",
            "Epoch 42/150\n",
            "6090/6090 [==============================] - 103s 17ms/step - loss: 0.2552 - accuracy: 0.7665 - f1_score: 0.7447 - val_loss: 0.2655 - val_accuracy: 0.7459 - val_f1_score: 0.7383\n",
            "Epoch 43/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2547 - accuracy: 0.7599 - f1_score: 0.7451 - val_loss: 0.2681 - val_accuracy: 0.7511 - val_f1_score: 0.7376\n",
            "Epoch 44/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2544 - accuracy: 0.7760 - f1_score: 0.7458 - val_loss: 0.2824 - val_accuracy: 0.7682 - val_f1_score: 0.7282\n",
            "Epoch 45/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2703 - accuracy: 0.7759 - f1_score: 0.7297 - val_loss: 0.2819 - val_accuracy: 0.7590 - val_f1_score: 0.7267\n",
            "Epoch 46/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2507 - accuracy: 0.7762 - f1_score: 0.7489 - val_loss: 0.2774 - val_accuracy: 0.7354 - val_f1_score: 0.7272\n",
            "Epoch 47/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2498 - accuracy: 0.7652 - f1_score: 0.7503 - val_loss: 0.2674 - val_accuracy: 0.7498 - val_f1_score: 0.7377\n",
            "Epoch 48/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2450 - accuracy: 0.7759 - f1_score: 0.7551 - val_loss: 0.2641 - val_accuracy: 0.7597 - val_f1_score: 0.7410\n",
            "Epoch 49/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2515 - accuracy: 0.7736 - f1_score: 0.7484 - val_loss: 0.2679 - val_accuracy: 0.7426 - val_f1_score: 0.7355\n",
            "Epoch 50/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2522 - accuracy: 0.7553 - f1_score: 0.7480 - val_loss: 0.2798 - val_accuracy: 0.7131 - val_f1_score: 0.7218\n",
            "Epoch 51/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2599 - accuracy: 0.7391 - f1_score: 0.7400 - val_loss: 0.2888 - val_accuracy: 0.6960 - val_f1_score: 0.7139\n",
            "Epoch 52/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2688 - accuracy: 0.7202 - f1_score: 0.7312 - val_loss: 0.2966 - val_accuracy: 0.6809 - val_f1_score: 0.7065\n",
            "Epoch 53/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2642 - accuracy: 0.7281 - f1_score: 0.7357 - val_loss: 0.2732 - val_accuracy: 0.7282 - val_f1_score: 0.7294\n",
            "Epoch 54/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2502 - accuracy: 0.7632 - f1_score: 0.7499 - val_loss: 0.2647 - val_accuracy: 0.7498 - val_f1_score: 0.7378\n",
            "Epoch 55/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2457 - accuracy: 0.7719 - f1_score: 0.7544 - val_loss: 0.2630 - val_accuracy: 0.7551 - val_f1_score: 0.7404\n",
            "Epoch 56/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2423 - accuracy: 0.7767 - f1_score: 0.7579 - val_loss: 0.2636 - val_accuracy: 0.7479 - val_f1_score: 0.7384\n",
            "Epoch 57/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2430 - accuracy: 0.7732 - f1_score: 0.7570 - val_loss: 0.2613 - val_accuracy: 0.7676 - val_f1_score: 0.7434\n",
            "Epoch 58/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2537 - accuracy: 0.7834 - f1_score: 0.7461 - val_loss: 0.2576 - val_accuracy: 0.7846 - val_f1_score: 0.7475\n",
            "Epoch 59/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2496 - accuracy: 0.7814 - f1_score: 0.7507 - val_loss: 0.2580 - val_accuracy: 0.7538 - val_f1_score: 0.7436\n",
            "Epoch 60/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2528 - accuracy: 0.7539 - f1_score: 0.7472 - val_loss: 0.2813 - val_accuracy: 0.7045 - val_f1_score: 0.7214\n",
            "Epoch 61/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2808 - accuracy: 0.6984 - f1_score: 0.7192 - val_loss: 0.3004 - val_accuracy: 0.6664 - val_f1_score: 0.7039\n",
            "Epoch 62/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2788 - accuracy: 0.7034 - f1_score: 0.7212 - val_loss: 0.2695 - val_accuracy: 0.7249 - val_f1_score: 0.7341\n",
            "Epoch 63/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2569 - accuracy: 0.7585 - f1_score: 0.7428 - val_loss: 0.2832 - val_accuracy: 0.7623 - val_f1_score: 0.7252\n",
            "Epoch 64/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.3067 - accuracy: 0.7621 - f1_score: 0.6934 - val_loss: 0.3555 - val_accuracy: 0.7452 - val_f1_score: 0.6550\n",
            "Epoch 65/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.3140 - accuracy: 0.7609 - f1_score: 0.6858 - val_loss: 0.2775 - val_accuracy: 0.7643 - val_f1_score: 0.7318\n",
            "Epoch 66/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2548 - accuracy: 0.7724 - f1_score: 0.7455 - val_loss: 0.2709 - val_accuracy: 0.7308 - val_f1_score: 0.7331\n",
            "Epoch 67/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2540 - accuracy: 0.7475 - f1_score: 0.7461 - val_loss: 0.2743 - val_accuracy: 0.7209 - val_f1_score: 0.7293\n",
            "Epoch 68/150\n",
            "6090/6090 [==============================] - 107s 18ms/step - loss: 0.2505 - accuracy: 0.7517 - f1_score: 0.7494 - val_loss: 0.2722 - val_accuracy: 0.7308 - val_f1_score: 0.7325\n",
            "Epoch 69/150\n",
            "6090/6090 [==============================] - 106s 17ms/step - loss: 0.2490 - accuracy: 0.7565 - f1_score: 0.7509 - val_loss: 0.2715 - val_accuracy: 0.7269 - val_f1_score: 0.7320\n",
            "Epoch 70/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2445 - accuracy: 0.7599 - f1_score: 0.7554 - val_loss: 0.2708 - val_accuracy: 0.7282 - val_f1_score: 0.7330\n",
            "Epoch 71/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2442 - accuracy: 0.7619 - f1_score: 0.7557 - val_loss: 0.2705 - val_accuracy: 0.7354 - val_f1_score: 0.7331\n",
            "Epoch 72/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2414 - accuracy: 0.7737 - f1_score: 0.7584 - val_loss: 0.2641 - val_accuracy: 0.7617 - val_f1_score: 0.7415\n",
            "Epoch 73/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2475 - accuracy: 0.7829 - f1_score: 0.7525 - val_loss: 0.2657 - val_accuracy: 0.7689 - val_f1_score: 0.7405\n",
            "Epoch 74/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2475 - accuracy: 0.7836 - f1_score: 0.7524 - val_loss: 0.2634 - val_accuracy: 0.7663 - val_f1_score: 0.7407\n",
            "Epoch 75/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2407 - accuracy: 0.7836 - f1_score: 0.7595 - val_loss: 0.2659 - val_accuracy: 0.7505 - val_f1_score: 0.7386\n",
            "Epoch 76/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2407 - accuracy: 0.7755 - f1_score: 0.7592 - val_loss: 0.2632 - val_accuracy: 0.7511 - val_f1_score: 0.7403\n",
            "Epoch 77/150\n",
            "6090/6090 [==============================] - 104s 17ms/step - loss: 0.2373 - accuracy: 0.7818 - f1_score: 0.7627 - val_loss: 0.2654 - val_accuracy: 0.7649 - val_f1_score: 0.7415\n",
            "Epoch 78/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2587 - accuracy: 0.7818 - f1_score: 0.7413 - val_loss: 0.2918 - val_accuracy: 0.7728 - val_f1_score: 0.7212\n",
            "Epoch 79/150\n",
            "6090/6090 [==============================] - 105s 17ms/step - loss: 0.2827 - accuracy: 0.7750 - f1_score: 0.7174 - val_loss: 0.2613 - val_accuracy: 0.7774 - val_f1_score: 0.7489\n",
            "Epoch 80/150\n",
            "1015/6090 [====>.........................] - ETA: 1:10 - loss: 0.2485 - accuracy: 0.7882 - f1_score: 0.7514"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZjwqE74cbzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Need to use save weights because save_model doesn't work with custom loss functions\n",
        "#nf_model.save_weights(\"nf_model_deep_bigBatch_keyword.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W6badyXskvK",
        "colab_type": "text"
      },
      "source": [
        "### Make prediction & submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dUBUBUNxvlR",
        "colab_type": "code",
        "outputId": "1da32aa8-d998-4406-8dab-a77093ee6e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "sub_model = thin_model\n",
        "prediction_np = sub_model.predict_classes(make_X(test_df))\n",
        "#prediction_np = (prediction_np > 0.5 )\n",
        "prediction_df = pd.DataFrame(prediction_np,columns = ['target'])\n",
        "prediction_df['id'] = test_df.id\n",
        "#prediction_df.target = prediction_df.target.apply(lambda x : 1 if x==True else 0)\n",
        "prediction_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  id\n",
              "0       1   0\n",
              "1       1   2\n",
              "2       1   3\n",
              "3       1   9\n",
              "4       1  11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnvNAoU0EwIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_df.to_csv('submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU7RDCoSDukh",
        "colab_type": "code",
        "outputId": "bf33e6b3-b1a6-47ec-cc4e-688b052d23aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!kaggle competitions submit -c nlp-getting-started -f submission.csv -m \"neural_network, features = lemma_text_emb + keyword_emb + gen_features, batches of 1000\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}